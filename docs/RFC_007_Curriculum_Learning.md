# ğŸ“‘ MÄ°MARÄ° Ã–NERÄ°: AGIFORMER Faz 7 - "Curriculum Learning & Neuroplasticity"

**Tarih:** 23 KasÄ±m 2025
**Konu:** Ä°nsan Benzeri Ã–ÄŸrenme SÃ¼recinin (Pedagojik EÄŸitim) Mimariye Entegrasyonu
**Hedef:** Wernicke Afazisi (AnlamsÄ±z akÄ±cÄ±lÄ±k) sorununu Ã§Ã¶zmek ve semantik tutarlÄ±lÄ±ÄŸÄ± artÄ±rmak.

---

## 1. YÃ¶netici Ã–zeti (Executive Summary)
Mevcut AGIFORMER mimarisi (Byte-Level + Hebbian Memory), TÃ¼rkÃ§enin morfolojik yapÄ±sÄ±nÄ± (mekanik zeka) Ã§Ã¶zmÃ¼ÅŸtÃ¼r. Ancak model, doÄŸrudan karmaÅŸÄ±k veriyle (Wikipedia) eÄŸitildiÄŸi iÃ§in kelime anlamlarÄ±nÄ± (semantik zeka) oturtmakta zorlanmaktadÄ±r.

Bu Ã¶neri, eÄŸitimi **3 AÅŸamalÄ± MÃ¼fredat (Curriculum)** sistemine dÃ¶nÃ¼ÅŸtÃ¼rmeyi ve modelin hafÄ±za plastisitesini (deÄŸiÅŸebilirliÄŸini) eÄŸitim sÃ¼resince dinamik olarak yÃ¶netmeyi hedefler.

---

## 2. Veri Mimarisi: AÅŸamalÄ± MÃ¼fredat (Curriculum Data Pipeline)

Modelin eÄŸitim verisi, rastgele bir akÄ±ÅŸ yerine, basitten karmaÅŸÄ±ÄŸa doÄŸru giden bir sÄ±ralamaya tabi tutulacaktÄ±r.

### Yeni ModÃ¼l: `src/data/curriculum.py`

Bu modÃ¼l, eÄŸitim adÄ±mÄ±na (`global_step`) gÃ¶re veri kaynaÄŸÄ±nÄ± dinamik olarak deÄŸiÅŸtiren bir `CurriculumDataLoader` sÄ±nÄ±fÄ± iÃ§erecektir.

*   **AÅŸama 1: Lexical Grounding (SÃ¶zlÃ¼k AÅŸamasÄ±)**
    *   **Kaynak:** TDK SÃ¶zlÃ¼k TanÄ±mlarÄ±, Wiktionary (Tr).
    *   **Ä°Ã§erik:** `Kelime: TanÄ±m.` formatÄ±nda basit yapÄ±taÅŸlarÄ±.
    *   **AmaÃ§:** Byte kombinasyonlarÄ±nÄ±n (kelimelerin) atomik anlamlarÄ±nÄ± sabitlemek.
    *   **SÃ¼re:** Ä°lk %10 - %15 adÄ±m.

*   **AÅŸama 2: Syntactic Scaffolding (Sentaks Ä°skelesi)**
    *   **Kaynak:** Ã‡ocuk Hikayeleri, Basit Haber Metinleri.
    *   **Ä°Ã§erik:** DÃ¼ÅŸÃ¼k entropili, Ã–zne-Nesne-YÃ¼klem kurallarÄ±na sÄ±kÄ± sÄ±kÄ±ya uyan kÄ±sa cÃ¼mleler.
    *   **AmaÃ§:** Gramer kurallarÄ±nÄ± ve basit mantÄ±k iliÅŸkilerini oturtmak.
    *   **SÃ¼re:** %15 - %40 adÄ±m.

*   **AÅŸama 3: Semantic Expansion (Ansiklopedik GeniÅŸleme)**
    *   **Kaynak:** Wikipedia (TemizlenmiÅŸ), Bilimsel Makaleler.
    *   **Ä°Ã§erik:** YÃ¼ksek entropili, karmaÅŸÄ±k ve uzun metinler.
    *   **AmaÃ§:** DÃ¼nya bilgisini ve soyut kavramlarÄ± Ã¶ÄŸrenmek.
    *   **SÃ¼re:** %40 - %100 adÄ±m.

---

## 3. Model Mimarisi: NÃ¶roplastisite (Dynamic Hebbian Decay)

Ä°nsan beynindeki **"Ã‡ocukken hÄ±zlÄ± Ã¶ÄŸrenme/unutma, yetiÅŸkinken seÃ§ici Ã¶ÄŸrenme/hatÄ±rlama"** mekanizmasÄ±nÄ± simÃ¼le etmek iÃ§in `HebbianMemory` modÃ¼lÃ¼ gÃ¼ncellenmelidir.

### GÃ¼ncellenecek ModÃ¼l: `src/models/memory.py`

Mevcut `HebbianMemory` sÄ±nÄ±fÄ±na bir `plasticity_schedule` eklenecektir.

**Mekanik DeÄŸiÅŸiklik:**
Åu anki sabit veya serbest Ã¶ÄŸrenilen `lambda` (decay) parametresi yerine, eÄŸitim adÄ±mÄ±na baÄŸlÄ± bir Ã§arpan (scalar) eklenecektir.

$$
M_t = (\lambda \cdot \alpha_t) M_{t-1} + (1 - \lambda) (K_t V_t^T)
$$

Burada $\alpha_t$ (Alpha), zamanla azalan bir **Plastisite KatsayÄ±sÄ±dÄ±r.**

*   **Ã‡ocukluk (Stage 1):** $\alpha \approx 0.1$ (HafÄ±za Ã§ok geÃ§irgen, her ÅŸeyi yazÄ±yor, Ã§abuk unutuyor).
*   **GenÃ§lik (Stage 2):** $\alpha \approx 0.5$ (Denge).
*   **YetiÅŸkinlik (Stage 3):** $\alpha \rightarrow 0.99$ (HafÄ±za direnÃ§li, sadece Ã§ok gÃ¼Ã§lÃ¼ sinyaller (gradients) hafÄ±zayÄ± deÄŸiÅŸtirebilir).

---

## 4. Uygulama PlanÄ± (Implementation Tasks)

GeliÅŸtirici ekip iÃ§in iÅŸ paketleri:

### GÃ¶rev 1: Veri HazÄ±rlÄ±ÄŸÄ± (`data`)
*   [ ] `src/data/curriculum.py` oluÅŸturulmasÄ±.
*   [ ] Hugging Face Ã¼zerinden `turkish-dictionary` ve `turkish-children-stories` veri setlerinin entegrasyonu.
*   [ ] `Wikipedia` veri setinin (mevcut clean script ile) son aÅŸama olarak baÄŸlanmasÄ±.

### GÃ¶rev 2: HafÄ±za ModÃ¼lÃ¼ GÃ¼ncellemesi (`model`)
*   [ ] `src/models/memory.py` iÃ§ine `set_plasticity(step)` metodunun eklenmesi.
*   [ ] `forward` fonksiyonunda `lambda` parametresinin dÄ±ÅŸarÄ±dan gelen katsayÄ± ile manipÃ¼le edilmesi.

### GÃ¶rev 3: EÄŸitim DÃ¶ngÃ¼sÃ¼ (`train`)
*   [ ] Yeni `train_curriculum.py` scriptinin yazÄ±lmasÄ±.
*   [ ] EÄŸitim dÃ¶ngÃ¼sÃ¼nde her N adÄ±mda bir veri yÃ¼kleyicinin (DataLoader) ve Plastisite katsayÄ±sÄ±nÄ±n gÃ¼ncellenmesi mantÄ±ÄŸÄ±nÄ±n kurulmasÄ±.

---

## 5. Beklenen Etki (Impact Analysis)

Bu mimari deÄŸiÅŸiklik uygulandÄ±ÄŸÄ±nda:
1.  **HalÃ¼sinasyon AzalmasÄ±:** Model, kelime kÃ¶klerini ilk aÅŸamada "ezberlediÄŸi" iÃ§in, olmayan kelimeler (Ã¶rn: *ekrekiyetin*) tÃ¼retme oranÄ± dÃ¼ÅŸecektir.
2.  **MantÄ±ksal TutarlÄ±lÄ±k:** Basit cÃ¼mlelerden karmaÅŸÄ±ÄŸa geÃ§iÅŸ, modelin "cÃ¼mlenin sonunu getirme" yeteneÄŸini gÃ¼Ã§lendirecektir.
3.  **Konverjans HÄ±zÄ±:** BaÅŸlangÄ±Ã§ta basit veri kullanÄ±ldÄ±ÄŸÄ± iÃ§in Loss deÄŸeri Ã§ok daha hÄ±zlÄ± dÃ¼ÅŸecek, eÄŸitim maliyeti azalacaktÄ±r.
