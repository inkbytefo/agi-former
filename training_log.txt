`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'wikipedia' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
============================================================
KAŞGARLI TESTİ - Turkish Wikipedia Benchmark
============================================================
Model: 31,199,792 parameters
Device: cuda
Downloading OFFICIAL Wikipedia (Turkish) dataset...
Fallback: Using 'wikimedia/wikipedia' dataset...
Processing Wikipedia articles (High Quality)...
  0%|          | 0/150 [00:00<?, ?MB/s]  0%|          | 0.10750484466552734/150 [00:00<17:25,  6.98s/MB]  0%|          | 0.710601806640625/150 [00:00<02:17,  1.09MB/s]    1%|          | 1.604787826538086/150 [00:00<00:58,  2.54MB/s]  2%|▏         | 2.374574661254883/150 [00:01<00:40,  3.62MB/s]  2%|▏         | 3.1522598266601562/150 [00:01<00:32,  4.56MB/s]  3%|▎         | 3.8745994567871094/150 [00:01<00:29,  5.02MB/s]  3%|▎         | 4.866791725158691/150 [00:01<00:23,  6.25MB/s]   4%|▍         | 5.716092109680176/150 [00:01<00:21,  6.83MB/s]  4%|▍         | 6.520505905151367/150 [00:01<00:20,  6.90MB/s]  5%|▍         | 7.299197196960449/150 [00:01<00:27,  5.20MB/s]  5%|▌         | 7.937695503234863/150 [00:02<00:36,  3.93MB/s]  6%|▌         | 8.57540225982666/150 [00:02<00:32,  4.37MB/s]   6%|▌         | 9.233001708984375/150 [00:02<00:29,  4.83MB/s]  7%|▋         | 10.029244422912598/150 [00:02<00:25,  5.54MB/s]  7%|▋         | 10.675081253051758/150 [00:02<00:29,  4.72MB/s]  8%|▊         | 11.578493118286133/150 [00:02<00:24,  5.68MB/s]  8%|▊         | 12.479269981384277/150 [00:02<00:21,  6.46MB/s]  9%|▉         | 13.367154121398926/150 [00:02<00:19,  7.08MB/s] 10%|▉         | 14.32779598236084/150 [00:02<00:17,  7.74MB/s]  10%|█         | 15.30449390411377/150 [00:03<00:16,  8.28MB/s] 11%|█         | 16.294245719909668/150 [00:03<00:15,  8.68MB/s] 11%|█▏        | 17.226754188537598/150 [00:03<00:15,  8.38MB/s] 12%|█▏        | 18.16454792022705/150 [00:03<00:15,  8.64MB/s]  13%|█▎        | 19.051008224487305/150 [00:03<00:15,  8.48MB/s] 13%|█▎        | 20.05092430114746/150 [00:03<00:14,  8.89MB/s]  14%|█▍        | 20.974742889404297/150 [00:03<00:22,  5.77MB/s] 14%|█▍        | 21.71128273010254/150 [00:04<00:26,  4.80MB/s]  15%|█▍        | 22.345651626586914/150 [00:04<00:31,  4.09MB/s] 15%|█▌        | 22.894097328186035/150 [00:04<00:29,  4.33MB/s] 16%|█▌        | 23.42781352996826/150 [00:04<00:34,  3.70MB/s]  16%|█▌        | 23.872050285339355/150 [00:04<00:35,  3.56MB/s] 16%|█▋        | 24.59122657775879/150 [00:04<00:29,  4.30MB/s]  17%|█▋        | 25.243915557861328/150 [00:05<00:26,  4.77MB/s] 17%|█▋        | 25.9463472366333/150 [00:05<00:23,  5.26MB/s]   18%|█▊        | 26.674297332763672/150 [00:05<00:21,  5.76MB/s] 18%|█▊        | 27.345571517944336/150 [00:05<00:20,  6.01MB/s] 19%|█▊        | 27.98288059234619/150 [00:05<00:20,  5.84MB/s]  19%|█▉        | 28.710928916931152/150 [00:05<00:19,  6.10MB/s] 20%|█▉        | 29.351841926574707/150 [00:05<00:23,  5.23MB/s] 20%|█▉        | 29.91164207458496/150 [00:05<00:26,  4.57MB/s]  20%|██        | 30.40180015563965/150 [00:06<00:26,  4.57MB/s] 21%|██        | 30.88877296447754/150 [00:06<00:25,  4.63MB/s] 21%|██        | 31.51014232635498/150 [00:06<00:23,  5.04MB/s] 21%|██▏       | 32.079365730285645/150 [00:06<00:28,  4.18MB/s] 22%|██▏       | 32.54075241088867/150 [00:06<00:27,  4.27MB/s]  22%|██▏       | 32.99704837799072/150 [00:06<00:26,  4.34MB/s] 22%|██▏       | 33.52517127990723/150 [00:06<00:25,  4.59MB/s] 23%|██▎       | 34.02837944030762/150 [00:06<00:34,  3.40MB/s] 23%|██▎       | 34.435903549194336/150 [00:07<00:51,  2.25MB/s] 23%|██▎       | 34.87253379821777/150 [00:07<00:44,  2.60MB/s]  24%|██▎       | 35.28614044189453/150 [00:07<00:39,  2.89MB/s] 24%|██▍       | 35.65873146057129/150 [00:07<00:38,  3.01MB/s] 24%|██▍       | 36.47077560424805/150 [00:07<00:27,  4.16MB/s] 25%|██▍       | 37.0985631942749/150 [00:07<00:24,  4.66MB/s]  25%|██▌       | 37.73994255065918/150 [00:07<00:21,  5.11MB/s] 26%|██▌       | 38.29897975921631/150 [00:08<00:21,  5.14MB/s] 26%|██▌       | 38.85487365722656/150 [00:08<00:24,  4.50MB/s] 26%|██▋       | 39.44769287109375/150 [00:08<00:23,  4.70MB/s] 27%|██▋       | 39.95656776428223/150 [00:08<00:28,  3.91MB/s] 27%|██▋       | 40.44009876251221/150 [00:08<00:26,  4.11MB/s] 27%|██▋       | 40.90411567687988/150 [00:08<00:26,  4.11MB/s] 28%|██▊       | 41.341673851013184/150 [00:09<01:02,  1.74MB/s] 28%|██▊       | 41.738173484802246/150 [00:09<00:53,  2.03MB/s] 28%|██▊       | 42.19325065612793/150 [00:09<00:44,  2.43MB/s]  28%|██▊       | 42.68416881561279/150 [00:09<00:37,  2.88MB/s] 29%|██▉       | 43.39346408843994/150 [00:09<00:28,  3.76MB/s] 29%|██▉       | 43.993910789489746/150 [00:09<00:25,  4.17MB/s] 30%|██▉       | 44.5068473815918/150 [00:10<00:27,  3.87MB/s]   30%|██▉       | 44.97859764099121/150 [00:10<00:27,  3.79MB/s] 30%|███       | 45.4765100479126/150 [00:10<00:25,  4.07MB/s]  31%|███       | 46.0643253326416/150 [00:10<00:22,  4.52MB/s] 31%|███       | 46.55692100524902/150 [00:10<00:25,  4.08MB/s] 31%|███▏      | 47.00606632232666/150 [00:10<00:26,  3.88MB/s] 32%|███▏      | 47.42543697357178/150 [00:10<00:27,  3.74MB/s] 32%|███▏      | 48.04682445526123/150 [00:10<00:23,  4.34MB/s] 32%|███▏      | 48.52279090881348/150 [00:11<00:26,  3.90MB/s] 33%|███▎      | 48.99432373046875/150 [00:11<00:24,  4.10MB/s] 33%|███▎      | 49.515403747558594/150 [00:11<00:22,  4.39MB/s] 33%|███▎      | 49.990264892578125/150 [00:11<00:33,  3.03MB/s] 34%|███▎      | 50.370750427246094/150 [00:11<00:34,  2.87MB/s] 34%|███▍      | 50.70924377441406/150 [00:11<00:34,  2.85MB/s]  34%|███▍      | 51.2225980758667/150 [00:11<00:29,  3.36MB/s]  34%|███▍      | 51.62378406524658/150 [00:11<00:27,  3.52MB/s] 35%|███▍      | 52.01619052886963/150 [00:12<00:28,  3.40MB/s] 35%|███▍      | 52.404852867126465/150 [00:12<00:27,  3.52MB/s] 35%|███▌      | 53.014159202575684/150 [00:12<00:23,  4.20MB/s] 36%|███▌      | 53.454511642456055/150 [00:12<00:23,  4.17MB/s] 36%|███▌      | 54.06883525848389/150 [00:12<00:20,  4.71MB/s]  36%|███▋      | 54.58061122894287/150 [00:12<00:20,  4.64MB/s] 37%|███▋      | 55.11492347717285/150 [00:12<00:19,  4.83MB/s] 37%|███▋      | 55.63825702667236/150 [00:12<00:19,  4.90MB/s] 37%|███▋      | 56.134825706481934/150 [00:12<00:19,  4.72MB/s] 38%|███▊      | 56.700557708740234/150 [00:13<00:18,  4.98MB/s] 38%|███▊      | 57.216803550720215/150 [00:13<00:20,  4.63MB/s] 38%|███▊      | 57.69609832763672/150 [00:13<00:30,  3.04MB/s]  39%|███▊      | 58.10493850708008/150 [00:13<00:28,  3.24MB/s] 39%|███▉      | 58.60084819793701/150 [00:13<00:25,  3.62MB/s] 39%|███▉      | 59.03559494018555/150 [00:13<00:25,  3.55MB/s] 40%|███▉      | 59.59762001037598/150 [00:13<00:22,  4.05MB/s] 40%|████      | 60.04722595214844/150 [00:14<00:25,  3.51MB/s] 40%|████      | 60.43868446350098/150 [00:14<00:27,  3.31MB/s] 41%|████      | 60.844109535217285/150 [00:14<00:25,  3.48MB/s] 41%|████      | 61.37219429016113/150 [00:14<00:22,  3.92MB/s]  41%|████▏     | 61.88821983337402/150 [00:14<00:20,  4.23MB/s] 42%|████▏     | 62.385332107543945/150 [00:14<00:19,  4.42MB/s] 42%|████▏     | 62.9165735244751/150 [00:14<00:18,  4.66MB/s]   42%|████▏     | 63.40946960449219/150 [00:14<00:18,  4.70MB/s] 43%|████▎     | 64.10043048858643/150 [00:14<00:16,  5.33MB/s] 43%|████▎     | 65.00258922576904/150 [00:15<00:13,  6.40MB/s] 44%|████▍     | 65.66254901885986/150 [00:15<00:13,  6.25MB/s] 44%|████▍     | 66.51278972625732/150 [00:15<00:12,  6.90MB/s] 45%|████▍     | 67.21452522277832/150 [00:15<00:11,  6.91MB/s] 45%|████▌     | 67.91572093963623/150 [00:15<00:14,  5.67MB/s] 46%|████▌     | 68.76001358032227/150 [00:15<00:12,  6.36MB/s] 46%|████▋     | 69.5694580078125/150 [00:15<00:11,  6.81MB/s]  47%|████▋     | 70.41977024078369/150 [00:15<00:10,  7.27MB/s] 47%|████▋     | 71.18005561828613/150 [00:15<00:12,  6.41MB/s] 48%|████▊     | 71.98577213287354/150 [00:16<00:11,  6.82MB/s] 49%|████▊     | 72.77844905853271/150 [00:16<00:10,  7.12MB/s] 49%|████▉     | 73.70130252838135/150 [00:16<00:09,  7.70MB/s] 50%|████▉     | 74.5741319656372/150 [00:16<00:09,  7.99MB/s]  50%|█████     | 75.42684078216553/150 [00:16<00:09,  8.14MB/s] 51%|█████     | 76.30333137512207/150 [00:16<00:08,  8.31MB/s] 51%|█████▏    | 77.20914459228516/150 [00:16<00:08,  8.53MB/s] 52%|█████▏    | 78.10640335083008/150 [00:16<00:08,  8.36MB/s] 53%|█████▎    | 78.9503755569458/150 [00:16<00:08,  8.25MB/s]  53%|█████▎    | 79.78044986724854/150 [00:16<00:09,  7.79MB/s] 54%|█████▎    | 80.59012413024902/150 [00:17<00:08,  7.86MB/s] 54%|█████▍    | 81.38253688812256/150 [00:17<00:08,  7.78MB/s] 55%|█████▍    | 82.16629219055176/150 [00:17<00:09,  6.98MB/s] 55%|█████▌    | 82.88565158843994/150 [00:17<00:09,  6.94MB/s] 56%|█████▌    | 83.59306240081787/150 [00:17<00:11,  5.62MB/s] 56%|█████▌    | 84.22493553161621/150 [00:17<00:11,  5.79MB/s] 57%|█████▋    | 84.84284400939941/150 [00:17<00:12,  5.40MB/s] 57%|█████▋    | 85.42567253112793/150 [00:17<00:12,  5.23MB/s] 57%|█████▋    | 86.05116176605225/150 [00:18<00:11,  5.48MB/s] 58%|█████▊    | 86.8199110031128/150 [00:18<00:10,  6.06MB/s]  58%|█████▊    | 87.51780414581299/150 [00:18<00:09,  6.30MB/s] 59%|█████▉    | 88.3263988494873/150 [00:18<00:09,  6.80MB/s]  59%|█████▉    | 89.01999855041504/150 [00:18<00:10,  5.88MB/s] 60%|█████▉    | 89.63853549957275/150 [00:18<00:10,  5.64MB/s] 60%|██████    | 90.42854022979736/150 [00:18<00:09,  6.22MB/s] 61%|██████    | 91.22104072570801/150 [00:18<00:08,  6.67MB/s] 61%|██████▏   | 91.93861293792725/150 [00:18<00:08,  6.72MB/s] 62%|██████▏   | 92.68936538696289/150 [00:19<00:08,  6.94MB/s] 62%|██████▏   | 93.52275657653809/150 [00:19<00:07,  7.33MB/s] 63%|██████▎   | 94.34886360168457/150 [00:19<00:07,  7.59MB/s] 63%|██████▎   | 95.11664581298828/150 [00:19<00:07,  7.09MB/s] 64%|██████▍   | 95.88203620910645/150 [00:19<00:07,  7.11MB/s] 64%|██████▍   | 96.69420528411865/150 [00:19<00:07,  7.39MB/s] 65%|██████▍   | 97.46099185943604/150 [00:19<00:10,  5.06MB/s] 66%|██████▌   | 98.3910608291626/150 [00:19<00:08,  5.98MB/s]  66%|██████▌   | 99.1035852432251/150 [00:20<00:09,  5.48MB/s] 66%|██████▋   | 99.7322359085083/150 [00:20<00:09,  5.26MB/s] 67%|██████▋   | 100.6501054763794/150 [00:20<00:08,  6.16MB/s] 68%|██████▊   | 101.5075569152832/150 [00:20<00:07,  6.76MB/s] 68%|██████▊   | 102.24250030517578/150 [00:20<00:06,  6.89MB/s] 69%|██████▉   | 103.1852855682373/150 [00:20<00:06,  7.57MB/s]  69%|██████▉   | 104.109375/150 [00:20<00:05,  8.00MB/s]        70%|██████▉   | 104.93761157989502/150 [00:20<00:05,  7.62MB/s] 71%|███████   | 105.75645542144775/150 [00:20<00:05,  7.77MB/s] 71%|███████   | 106.5956449508667/150 [00:21<00:05,  7.94MB/s]  72%|███████▏  | 107.44654273986816/150 [00:21<00:05,  8.09MB/s] 72%|███████▏  | 108.26797008514404/150 [00:21<00:05,  7.51MB/s] 73%|███████▎  | 109.10014533996582/150 [00:21<00:05,  7.72MB/s] 73%|███████▎  | 109.95930862426758/150 [00:21<00:05,  7.93MB/s] 74%|███████▍  | 110.76524543762207/150 [00:21<00:05,  7.76MB/s] 74%|███████▍  | 111.54912090301514/150 [00:21<00:05,  7.05MB/s] 75%|███████▍  | 112.27245998382568/150 [00:21<00:05,  6.74MB/s] 75%|███████▌  | 112.96138954162598/150 [00:22<00:05,  6.45MB/s] 76%|███████▌  | 113.61640453338623/150 [00:22<00:06,  5.41MB/s] 76%|███████▌  | 114.2371597290039/150 [00:22<00:06,  5.58MB/s]  77%|███████▋  | 115.12478637695312/150 [00:22<00:05,  6.42MB/s] 77%|███████▋  | 115.79769706726074/150 [00:22<00:05,  6.35MB/s] 78%|███████▊  | 116.58157730102539/150 [00:22<00:04,  6.75MB/s] 78%|███████▊  | 117.33320331573486/150 [00:22<00:04,  6.94MB/s] 79%|███████▉  | 118.16822052001953/150 [00:22<00:04,  7.34MB/s] 79%|███████▉  | 118.9148530960083/150 [00:22<00:04,  7.30MB/s]  80%|███████▉  | 119.67426872253418/150 [00:23<00:04,  7.34MB/s] 80%|████████  | 120.42044830322266/150 [00:23<00:04,  7.35MB/s] 81%|████████  | 121.16299438476562/150 [00:23<00:03,  7.36MB/s] 81%|████████▏ | 121.93414115905762/150 [00:23<00:03,  7.42MB/s] 82%|████████▏ | 122.77831554412842/150 [00:23<00:03,  7.71MB/s] 82%|████████▏ | 123.56369972229004/150 [00:23<00:04,  6.50MB/s] 83%|████████▎ | 124.25193405151367/150 [00:23<00:03,  6.60MB/s] 83%|████████▎ | 124.94664764404297/150 [00:23<00:03,  6.67MB/s] 84%|████████▍ | 125.63570213317871/150 [00:23<00:03,  6.14MB/s] 84%|████████▍ | 126.43475341796875/150 [00:24<00:03,  6.62MB/s] 85%|████████▍ | 127.22398948669434/150 [00:24<00:03,  6.93MB/s] 85%|████████▌ | 127.93247699737549/150 [00:24<00:03,  6.63MB/s] 86%|████████▌ | 128.60877132415771/150 [00:24<00:03,  5.85MB/s] 86%|████████▌ | 129.2597198486328/150 [00:24<00:03,  6.01MB/s]  87%|████████▋ | 129.88454151153564/150 [00:24<00:03,  5.76MB/s] 87%|████████▋ | 130.4776153564453/150 [00:24<00:03,  5.60MB/s]  87%|████████▋ | 131.06349658966064/150 [00:24<00:03,  5.67MB/s] 88%|████████▊ | 131.7430772781372/150 [00:24<00:03,  5.97MB/s]  88%|████████▊ | 132.37491703033447/150 [00:25<00:03,  5.17MB/s] 89%|████████▊ | 132.98953437805176/150 [00:25<00:04,  4.08MB/s] 89%|████████▉ | 133.45145511627197/150 [00:25<00:04,  3.84MB/s] 89%|████████▉ | 133.87644958496094/150 [00:25<00:04,  3.91MB/s] 90%|████████▉ | 134.4502182006836/150 [00:25<00:03,  4.34MB/s]  90%|█████████ | 135.0872573852539/150 [00:25<00:03,  4.86MB/s] 91%|█████████ | 135.88038063049316/150 [00:25<00:02,  5.67MB/s] 91%|█████████ | 136.54689502716064/150 [00:25<00:02,  5.37MB/s] 91%|█████████▏| 137.11184978485107/150 [00:26<00:02,  4.97MB/s] 92%|█████████▏| 137.6303415298462/150 [00:26<00:02,  4.73MB/s]  92%|█████████▏| 138.1228485107422/150 [00:26<00:02,  4.17MB/s] 92%|█████████▏| 138.55857944488525/150 [00:26<00:02,  3.91MB/s] 93%|█████████▎| 139.2814826965332/150 [00:26<00:02,  4.71MB/s]  93%|█████████▎| 139.8760690689087/150 [00:26<00:02,  5.02MB/s] 94%|█████████▍| 140.76264095306396/150 [00:26<00:01,  6.03MB/s] 94%|█████████▍| 141.4645290374756/150 [00:26<00:01,  6.29MB/s]  95%|█████████▍| 142.1280746459961/150 [00:27<00:01,  6.35MB/s] 95%|█████████▌| 142.80875492095947/150 [00:27<00:01,  6.47MB/s] 96%|█████████▌| 143.57889652252197/150 [00:27<00:00,  6.81MB/s] 96%|█████████▌| 144.30450820922852/150 [00:27<00:00,  6.94MB/s] 97%|█████████▋| 145.23771286010742/150 [00:27<00:00,  7.64MB/s] 97%|█████████▋| 146.00784492492676/150 [00:27<00:00,  7.37MB/s] 98%|█████████▊| 146.75300979614258/150 [00:27<00:00,  6.98MB/s] 98%|█████████▊| 147.45923614501953/150 [00:27<00:00,  6.93MB/s] 99%|█████████▉| 148.17523765563965/150 [00:27<00:00,  6.78MB/s] 99%|█████████▉| 148.8883876800537/150 [00:28<00:00,  6.50MB/s] 100%|█████████▉| 149.55185222625732/150 [00:28<00:00,  5.85MB/s]/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/std.py:636: TqdmWarning: clamping frac to range [0, 1]
  full_bar = Bar(frac,
100%|██████████| 150.0022792816162/150 [00:28<00:00,  5.31MB/s] 
/home/ubuntu/agi-former/train_turkish.py:78: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler() # AMP Scaler
/home/ubuntu/agi-former/train_turkish.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):
Saving binary files...
✅ Dataset Ready: 149.4MB Train, 7.9MB Val
Step 0: Loss = 5.5667 | BPC = 8.0311 | LR = 3.00e-06
Step 10: Loss = 5.1596 | BPC = 7.4438 | LR = 3.30e-05
Step 20: Loss = 4.7279 | BPC = 6.8210 | LR = 6.30e-05
Step 30: Loss = 4.3367 | BPC = 6.2565 | LR = 9.30e-05
Step 40: Loss = 4.0568 | BPC = 5.8527 | LR = 1.23e-04
Step 50: Loss = 3.6685 | BPC = 5.2925 | LR = 1.53e-04
Step 60: Loss = 3.4710 | BPC = 5.0076 | LR = 1.83e-04
Step 70: Loss = 3.5578 | BPC = 5.1329 | LR = 2.13e-04
Step 80: Loss = 3.4173 | BPC = 4.9301 | LR = 2.43e-04
Step 90: Loss = 3.3243 | BPC = 4.7960 | LR = 2.73e-04
Step 100: Loss = 3.1973 | BPC = 4.6127 | LR = 3.00e-04
Step 110: Loss = 3.3798 | BPC = 4.8760 | LR = 3.00e-04
Step 120: Loss = 2.8917 | BPC = 4.1718 | LR = 3.00e-04
Step 130: Loss = 2.7937 | BPC = 4.0305 | LR = 3.00e-04
Step 140: Loss = 2.9610 | BPC = 4.2717 | LR = 3.00e-04
Step 150: Loss = 2.6031 | BPC = 3.7555 | LR = 3.00e-04
Step 160: Loss = 2.6930 | BPC = 3.8851 | LR = 3.00e-04
Step 170: Loss = 2.5060 | BPC = 3.6153 | LR = 3.00e-04
Step 180: Loss = 2.6661 | BPC = 3.8464 | LR = 3.00e-04
Step 190: Loss = 2.8579 | BPC = 4.1231 | LR = 3.00e-04
Step 200: Loss = 2.4321 | BPC = 3.5088 | LR = 3.00e-04
-- VALIDATION: Loss = 2.4026 | BPC = 3.4662 --
Saved best model (Turkish).
Step 210: Loss = 2.4531 | BPC = 3.5391 | LR = 3.00e-04
Step 220: Loss = 2.4373 | BPC = 3.5163 | LR = 3.00e-04
Step 230: Loss = 2.3604 | BPC = 3.4053 | LR = 3.00e-04
Step 240: Loss = 2.4235 | BPC = 3.4963 | LR = 3.00e-04
Step 250: Loss = 2.2534 | BPC = 3.2510 | LR = 3.00e-04
Step 260: Loss = 2.2789 | BPC = 3.2878 | LR = 3.00e-04
Step 270: Loss = 2.3296 | BPC = 3.3609 | LR = 3.00e-04
Step 280: Loss = 2.2972 | BPC = 3.3142 | LR = 3.00e-04
Step 290: Loss = 2.3157 | BPC = 3.3409 | LR = 3.00e-04
Step 300: Loss = 2.1760 | BPC = 3.1392 | LR = 3.00e-04
Step 310: Loss = 2.2097 | BPC = 3.1879 | LR = 3.00e-04
Step 320: Loss = 2.4631 | BPC = 3.5535 | LR = 3.00e-04
Step 330: Loss = 2.3108 | BPC = 3.3337 | LR = 3.00e-04
Step 340: Loss = 2.2389 | BPC = 3.2301 | LR = 3.00e-04
Step 350: Loss = 2.2339 | BPC = 3.2228 | LR = 3.00e-04
Step 360: Loss = 2.2096 | BPC = 3.1878 | LR = 3.00e-04
Step 370: Loss = 2.2309 | BPC = 3.2186 | LR = 3.00e-04
Step 380: Loss = 2.1207 | BPC = 3.0595 | LR = 3.00e-04
Step 390: Loss = 2.2750 | BPC = 3.2822 | LR = 3.00e-04
Step 400: Loss = 2.1438 | BPC = 3.0929 | LR = 3.00e-04
-- VALIDATION: Loss = 2.1488 | BPC = 3.1001 --
Saved best model (Turkish).
Step 410: Loss = 2.1632 | BPC = 3.1208 | LR = 3.00e-04
Step 420: Loss = 2.1372 | BPC = 3.0834 | LR = 3.00e-04
Step 430: Loss = 2.1720 | BPC = 3.1336 | LR = 3.00e-04
Step 440: Loss = 2.1821 | BPC = 3.1481 | LR = 3.00e-04
Step 450: Loss = 2.4691 | BPC = 3.5622 | LR = 3.00e-04
Step 460: Loss = 2.1788 | BPC = 3.1434 | LR = 3.00e-04
Step 470: Loss = 2.0735 | BPC = 2.9914 | LR = 3.00e-04
Step 480: Loss = 2.1555 | BPC = 3.1097 | LR = 3.00e-04
Step 490: Loss = 2.6615 | BPC = 3.8397 | LR = 3.00e-04
Step 500: Loss = 2.1795 | BPC = 3.1444 | LR = 3.00e-04
Step 510: Loss = 2.0878 | BPC = 3.0120 | LR = 3.00e-04
Step 520: Loss = 2.2475 | BPC = 3.2424 | LR = 3.00e-04
Step 530: Loss = 2.1560 | BPC = 3.1105 | LR = 3.00e-04
Step 540: Loss = 2.3724 | BPC = 3.4227 | LR = 3.00e-04
Step 550: Loss = 1.9975 | BPC = 2.8818 | LR = 3.00e-04
Step 560: Loss = 2.1653 | BPC = 3.1239 | LR = 3.00e-04
Step 570: Loss = 2.3204 | BPC = 3.3476 | LR = 3.00e-04
Step 580: Loss = 2.0298 | BPC = 2.9283 | LR = 3.00e-04
Step 590: Loss = 2.0621 | BPC = 2.9750 | LR = 3.00e-04
Step 600: Loss = 2.1472 | BPC = 3.0978 | LR = 3.00e-04
-- VALIDATION: Loss = 2.0362 | BPC = 2.9376 --
Saved best model (Turkish).
Step 610: Loss = 2.3403 | BPC = 3.3763 | LR = 3.00e-04
Step 620: Loss = 2.0314 | BPC = 2.9307 | LR = 3.00e-04
Step 630: Loss = 1.9753 | BPC = 2.8497 | LR = 3.00e-04
Step 640: Loss = 2.2354 | BPC = 3.2250 | LR = 3.00e-04
Step 650: Loss = 2.0004 | BPC = 2.8859 | LR = 3.00e-04
Step 660: Loss = 1.9799 | BPC = 2.8564 | LR = 3.00e-04
Step 670: Loss = 2.1302 | BPC = 3.0732 | LR = 3.00e-04
Step 680: Loss = 2.0417 | BPC = 2.9456 | LR = 3.00e-04
Step 690: Loss = 1.9822 | BPC = 2.8596 | LR = 3.00e-04
Step 700: Loss = 2.0358 | BPC = 2.9370 | LR = 3.00e-04
Step 710: Loss = 2.3029 | BPC = 3.3224 | LR = 3.00e-04
Step 720: Loss = 1.9610 | BPC = 2.8291 | LR = 3.00e-04
Step 730: Loss = 2.0881 | BPC = 3.0124 | LR = 3.00e-04
Step 740: Loss = 2.2942 | BPC = 3.3099 | LR = 3.00e-04
Step 750: Loss = 1.9944 | BPC = 2.8773 | LR = 3.00e-04
Step 760: Loss = 2.0625 | BPC = 2.9755 | LR = 3.00e-04
Step 770: Loss = 2.2695 | BPC = 3.2742 | LR = 3.00e-04
Step 780: Loss = 2.0340 | BPC = 2.9344 | LR = 3.00e-04
Step 790: Loss = 2.3739 | BPC = 3.4248 | LR = 3.00e-04
Step 800: Loss = 2.0376 | BPC = 2.9396 | LR = 3.00e-04
-- VALIDATION: Loss = 1.9821 | BPC = 2.8596 --
Saved best model (Turkish).
Step 810: Loss = 2.0159 | BPC = 2.9083 | LR = 3.00e-04
Step 820: Loss = 2.0162 | BPC = 2.9088 | LR = 3.00e-04
Step 830: Loss = 2.2968 | BPC = 3.3136 | LR = 3.00e-04
Step 840: Loss = 1.8271 | BPC = 2.6359 | LR = 3.00e-04
Step 850: Loss = 1.8398 | BPC = 2.6543 | LR = 3.00e-04
Step 860: Loss = 1.9638 | BPC = 2.8331 | LR = 3.00e-04
Step 870: Loss = 2.0505 | BPC = 2.9583 | LR = 3.00e-04
Step 880: Loss = 1.9609 | BPC = 2.8289 | LR = 3.00e-04
Step 890: Loss = 1.9590 | BPC = 2.8262 | LR = 3.00e-04
Step 900: Loss = 2.3275 | BPC = 3.3579 | LR = 3.00e-04
Step 910: Loss = 2.2199 | BPC = 3.2026 | LR = 3.00e-04
Step 920: Loss = 1.8779 | BPC = 2.7092 | LR = 3.00e-04
Step 930: Loss = 2.1972 | BPC = 3.1699 | LR = 3.00e-04
Step 940: Loss = 1.9552 | BPC = 2.8207 | LR = 3.00e-04
Step 950: Loss = 1.9287 | BPC = 2.7825 | LR = 3.00e-04
Step 960: Loss = 1.8856 | BPC = 2.7204 | LR = 3.00e-04
Step 970: Loss = 1.9726 | BPC = 2.8459 | LR = 3.00e-04
Step 980: Loss = 1.8222 | BPC = 2.6289 | LR = 3.00e-04
Step 990: Loss = 1.9315 | BPC = 2.7865 | LR = 3.00e-04
Step 1000: Loss = 2.0780 | BPC = 2.9979 | LR = 3.00e-04
-- VALIDATION: Loss = 1.9220 | BPC = 2.7729 --
Saved best model (Turkish).
Step 1010: Loss = 2.1336 | BPC = 3.0781 | LR = 3.00e-04
Step 1020: Loss = 2.0179 | BPC = 2.9112 | LR = 3.00e-04
Step 1030: Loss = 1.9484 | BPC = 2.8109 | LR = 3.00e-04
Step 1040: Loss = 1.8173 | BPC = 2.6217 | LR = 3.00e-04
Step 1050: Loss = 1.8789 | BPC = 2.7106 | LR = 3.00e-04
Step 1060: Loss = 1.9016 | BPC = 2.7434 | LR = 3.00e-04
Step 1070: Loss = 2.1407 | BPC = 3.0883 | LR = 3.00e-04
Step 1080: Loss = 1.8383 | BPC = 2.6522 | LR = 3.00e-04
Step 1090: Loss = 2.0388 | BPC = 2.9414 | LR = 3.00e-04
Step 1100: Loss = 1.9277 | BPC = 2.7811 | LR = 3.00e-04
Step 1110: Loss = 1.9661 | BPC = 2.8364 | LR = 3.00e-04
Step 1120: Loss = 1.8048 | BPC = 2.6037 | LR = 3.00e-04
Step 1130: Loss = 1.9591 | BPC = 2.8264 | LR = 3.00e-04
Step 1140: Loss = 1.8351 | BPC = 2.6475 | LR = 3.00e-04
Step 1150: Loss = 1.8461 | BPC = 2.6634 | LR = 3.00e-04
Step 1160: Loss = 1.9882 | BPC = 2.8683 | LR = 3.00e-04
Step 1170: Loss = 1.7624 | BPC = 2.5427 | LR = 3.00e-04
Step 1180: Loss = 2.1502 | BPC = 3.1021 | LR = 3.00e-04
Step 1190: Loss = 1.9670 | BPC = 2.8378 | LR = 3.00e-04
Step 1200: Loss = 1.8421 | BPC = 2.6576 | LR = 3.00e-04
-- VALIDATION: Loss = 1.8622 | BPC = 2.6865 --
Saved best model (Turkish).
Step 1210: Loss = 2.0381 | BPC = 2.9404 | LR = 3.00e-04
Step 1220: Loss = 1.9327 | BPC = 2.7884 | LR = 3.00e-04
Step 1230: Loss = 2.0404 | BPC = 2.9437 | LR = 3.00e-04
Step 1240: Loss = 1.9075 | BPC = 2.7520 | LR = 3.00e-04
Step 1250: Loss = 1.8238 | BPC = 2.6312 | LR = 3.00e-04
Step 1260: Loss = 1.9110 | BPC = 2.7570 | LR = 3.00e-04
Step 1270: Loss = 1.8870 | BPC = 2.7223 | LR = 3.00e-04
Step 1280: Loss = 1.8769 | BPC = 2.7078 | LR = 3.00e-04
Step 1290: Loss = 1.8928 | BPC = 2.7308 | LR = 3.00e-04
Step 1300: Loss = 1.7886 | BPC = 2.5804 | LR = 3.00e-04
Step 1310: Loss = 1.8301 | BPC = 2.6402 | LR = 3.00e-04
Step 1320: Loss = 2.0952 | BPC = 3.0228 | LR = 3.00e-04
Step 1330: Loss = 2.0625 | BPC = 2.9755 | LR = 3.00e-04
Step 1340: Loss = 1.9492 | BPC = 2.8122 | LR = 3.00e-04
Step 1350: Loss = 1.8274 | BPC = 2.6364 | LR = 3.00e-04
Step 1360: Loss = 1.7035 | BPC = 2.4577 | LR = 3.00e-04
Step 1370: Loss = 2.2332 | BPC = 3.2219 | LR = 3.00e-04
Step 1380: Loss = 1.9255 | BPC = 2.7778 | LR = 3.00e-04
Step 1390: Loss = 1.9248 | BPC = 2.7768 | LR = 3.00e-04
Step 1400: Loss = 1.8272 | BPC = 2.6361 | LR = 3.00e-04
-- VALIDATION: Loss = 1.8249 | BPC = 2.6327 --
Saved best model (Turkish).
Step 1410: Loss = 2.1705 | BPC = 3.1313 | LR = 3.00e-04
Step 1420: Loss = 1.7921 | BPC = 2.5855 | LR = 3.00e-04
Step 1430: Loss = 1.9557 | BPC = 2.8215 | LR = 3.00e-04
Step 1440: Loss = 2.1134 | BPC = 3.0490 | LR = 3.00e-04
Step 1450: Loss = 2.2157 | BPC = 3.1965 | LR = 3.00e-04
Step 1460: Loss = 2.0693 | BPC = 2.9854 | LR = 3.00e-04
Step 1470: Loss = 2.0120 | BPC = 2.9027 | LR = 3.00e-04
Step 1480: Loss = 2.0534 | BPC = 2.9624 | LR = 3.00e-04
Step 1490: Loss = 1.7444 | BPC = 2.5166 | LR = 3.00e-04
Step 1500: Loss = 1.7571 | BPC = 2.5350 | LR = 3.00e-04
Step 1510: Loss = 1.7037 | BPC = 2.4579 | LR = 3.00e-04
Step 1520: Loss = 1.8336 | BPC = 2.6454 | LR = 3.00e-04
Step 1530: Loss = 1.8093 | BPC = 2.6103 | LR = 3.00e-04
Step 1540: Loss = 1.7801 | BPC = 2.5681 | LR = 3.00e-04
Step 1550: Loss = 1.7784 | BPC = 2.5657 | LR = 3.00e-04
Step 1560: Loss = 1.8184 | BPC = 2.6234 | LR = 3.00e-04
Step 1570: Loss = 1.8796 | BPC = 2.7117 | LR = 3.00e-04
Step 1580: Loss = 1.7887 | BPC = 2.5806 | LR = 3.00e-04
Step 1590: Loss = 1.6845 | BPC = 2.4302 | LR = 3.00e-04
Step 1600: Loss = 1.7910 | BPC = 2.5839 | LR = 3.00e-04
-- VALIDATION: Loss = 1.8150 | BPC = 2.6185 --
Saved best model (Turkish).
Step 1610: Loss = 1.9007 | BPC = 2.7421 | LR = 3.00e-04
Step 1620: Loss = 2.0477 | BPC = 2.9543 | LR = 3.00e-04
Step 1630: Loss = 1.6072 | BPC = 2.3187 | LR = 3.00e-04
Step 1640: Loss = 1.7796 | BPC = 2.5675 | LR = 3.00e-04
Step 1650: Loss = 1.8521 | BPC = 2.6720 | LR = 3.00e-04
Step 1660: Loss = 1.7944 | BPC = 2.5887 | LR = 3.00e-04
Step 1670: Loss = 1.7482 | BPC = 2.5222 | LR = 3.00e-04
Step 1680: Loss = 1.6680 | BPC = 2.4065 | LR = 3.00e-04
Step 1690: Loss = 1.7710 | BPC = 2.5549 | LR = 3.00e-04
Step 1700: Loss = 1.8859 | BPC = 2.7208 | LR = 3.00e-04
Step 1710: Loss = 1.8693 | BPC = 2.6969 | LR = 3.00e-04
Step 1720: Loss = 1.9042 | BPC = 2.7472 | LR = 3.00e-04
Step 1730: Loss = 1.9293 | BPC = 2.7834 | LR = 3.00e-04
Step 1740: Loss = 1.9316 | BPC = 2.7867 | LR = 3.00e-04
Step 1750: Loss = 1.7014 | BPC = 2.4546 | LR = 3.00e-04
Step 1760: Loss = 1.8980 | BPC = 2.7382 | LR = 3.00e-04
Step 1770: Loss = 1.6113 | BPC = 2.3247 | LR = 3.00e-04
Step 1780: Loss = 1.7774 | BPC = 2.5643 | LR = 3.00e-04
Step 1790: Loss = 1.7097 | BPC = 2.4665 | LR = 3.00e-04
Step 1800: Loss = 1.7083 | BPC = 2.4645 | LR = 3.00e-04
-- VALIDATION: Loss = 1.7789 | BPC = 2.5665 --
Saved best model (Turkish).
Step 1810: Loss = 1.7297 | BPC = 2.4955 | LR = 3.00e-04
Step 1820: Loss = 1.8688 | BPC = 2.6961 | LR = 3.00e-04
Step 1830: Loss = 1.8230 | BPC = 2.6300 | LR = 3.00e-04
Step 1840: Loss = 1.7355 | BPC = 2.5038 | LR = 3.00e-04
Step 1850: Loss = 1.8003 | BPC = 2.5973 | LR = 3.00e-04
Step 1860: Loss = 1.7676 | BPC = 2.5501 | LR = 3.00e-04
Step 1870: Loss = 1.8054 | BPC = 2.6046 | LR = 3.00e-04
Step 1880: Loss = 1.7113 | BPC = 2.4689 | LR = 3.00e-04
Step 1890: Loss = 1.8843 | BPC = 2.7185 | LR = 3.00e-04
Step 1900: Loss = 1.7524 | BPC = 2.5282 | LR = 3.00e-04
Step 1910: Loss = 1.7885 | BPC = 2.5803 | LR = 3.00e-04
Step 1920: Loss = 2.0284 | BPC = 2.9263 | LR = 3.00e-04
Step 1930: Loss = 1.6122 | BPC = 2.3259 | LR = 3.00e-04
Step 1940: Loss = 1.8094 | BPC = 2.6103 | LR = 3.00e-04
Step 1950: Loss = 1.7509 | BPC = 2.5260 | LR = 3.00e-04
Step 1960: Loss = 2.0155 | BPC = 2.9078 | LR = 3.00e-04
Step 1970: Loss = 1.7945 | BPC = 2.5889 | LR = 3.00e-04
Step 1980: Loss = 1.7654 | BPC = 2.5469 | LR = 3.00e-04
Step 1990: Loss = 1.6307 | BPC = 2.3527 | LR = 3.00e-04
Step 2000: Loss = 1.6437 | BPC = 2.3713 | LR = 3.00e-04
-- VALIDATION: Loss = 1.7366 | BPC = 2.5055 --
Saved best model (Turkish).
Step 2010: Loss = 1.7182 | BPC = 2.4788 | LR = 3.00e-04
Step 2020: Loss = 1.7460 | BPC = 2.5189 | LR = 3.00e-04
Step 2030: Loss = 1.7149 | BPC = 2.4740 | LR = 3.00e-04
Step 2040: Loss = 1.6781 | BPC = 2.4210 | LR = 3.00e-04
Step 2050: Loss = 1.6805 | BPC = 2.4245 | LR = 3.00e-04
Step 2060: Loss = 1.7008 | BPC = 2.4537 | LR = 3.00e-04
Step 2070: Loss = 1.7155 | BPC = 2.4749 | LR = 3.00e-04
Step 2080: Loss = 1.5488 | BPC = 2.2344 | LR = 3.00e-04
Step 2090: Loss = 1.8554 | BPC = 2.6768 | LR = 3.00e-04
Step 2100: Loss = 1.7439 | BPC = 2.5159 | LR = 3.00e-04
Step 2110: Loss = 1.7513 | BPC = 2.5266 | LR = 3.00e-04
Step 2120: Loss = 2.1803 | BPC = 3.1455 | LR = 3.00e-04
Step 2130: Loss = 1.8453 | BPC = 2.6622 | LR = 3.00e-04
Step 2140: Loss = 1.7079 | BPC = 2.4640 | LR = 3.00e-04
Step 2150: Loss = 1.9316 | BPC = 2.7866 | LR = 3.00e-04
Step 2160: Loss = 1.7453 | BPC = 2.5179 | LR = 3.00e-04
Step 2170: Loss = 1.6725 | BPC = 2.4129 | LR = 3.00e-04
Step 2180: Loss = 1.6366 | BPC = 2.3611 | LR = 3.00e-04
Step 2190: Loss = 1.6948 | BPC = 2.4451 | LR = 3.00e-04
Step 2200: Loss = 1.6158 | BPC = 2.3311 | LR = 3.00e-04
-- VALIDATION: Loss = 1.7210 | BPC = 2.4829 --
Saved best model (Turkish).
Step 2210: Loss = 1.7228 | BPC = 2.4855 | LR = 3.00e-04
Step 2220: Loss = 1.6794 | BPC = 2.4229 | LR = 3.00e-04
Step 2230: Loss = 1.7764 | BPC = 2.5628 | LR = 3.00e-04
Step 2240: Loss = 2.0679 | BPC = 2.9834 | LR = 3.00e-04
Step 2250: Loss = 1.7450 | BPC = 2.5175 | LR = 3.00e-04
Step 2260: Loss = 1.7407 | BPC = 2.5113 | LR = 3.00e-04
Step 2270: Loss = 1.7835 | BPC = 2.5730 | LR = 3.00e-04
Step 2280: Loss = 1.6756 | BPC = 2.4174 | LR = 3.00e-04
Step 2290: Loss = 1.7764 | BPC = 2.5629 | LR = 3.00e-04
Step 2300: Loss = 1.6127 | BPC = 2.3267 | LR = 3.00e-04
Step 2310: Loss = 2.2690 | BPC = 3.2735 | LR = 3.00e-04
Step 2320: Loss = 1.6714 | BPC = 2.4113 | LR = 3.00e-04
Step 2330: Loss = 1.7435 | BPC = 2.5154 | LR = 3.00e-04
Step 2340: Loss = 1.7532 | BPC = 2.5294 | LR = 3.00e-04
Step 2350: Loss = 2.1146 | BPC = 3.0507 | LR = 3.00e-04
Step 2360: Loss = 1.6177 | BPC = 2.3338 | LR = 3.00e-04
Step 2370: Loss = 1.7536 | BPC = 2.5299 | LR = 3.00e-04
Step 2380: Loss = 1.9502 | BPC = 2.8136 | LR = 3.00e-04
Step 2390: Loss = 1.6348 | BPC = 2.3585 | LR = 3.00e-04
Step 2400: Loss = 1.6915 | BPC = 2.4403 | LR = 3.00e-04
-- VALIDATION: Loss = 1.7014 | BPC = 2.4545 --
Saved best model (Turkish).
Step 2410: Loss = 1.7041 | BPC = 2.4585 | LR = 3.00e-04
Step 2420: Loss = 1.6518 | BPC = 2.3831 | LR = 3.00e-04
Step 2430: Loss = 1.7377 | BPC = 2.5069 | LR = 3.00e-04
Step 2440: Loss = 1.6683 | BPC = 2.4069 | LR = 3.00e-04
Step 2450: Loss = 1.7538 | BPC = 2.5302 | LR = 3.00e-04
Step 2460: Loss = 1.9083 | BPC = 2.7531 | LR = 3.00e-04
Step 2470: Loss = 1.8113 | BPC = 2.6132 | LR = 3.00e-04
Step 2480: Loss = 1.8466 | BPC = 2.6641 | LR = 3.00e-04
Step 2490: Loss = 1.6962 | BPC = 2.4470 | LR = 3.00e-04
Step 2500: Loss = 1.6502 | BPC = 2.3807 | LR = 3.00e-04
Step 2510: Loss = 1.8032 | BPC = 2.6015 | LR = 3.00e-04
Step 2520: Loss = 1.5976 | BPC = 2.3049 | LR = 3.00e-04
Step 2530: Loss = 1.8156 | BPC = 2.6193 | LR = 3.00e-04
Step 2540: Loss = 1.6353 | BPC = 2.3593 | LR = 3.00e-04
Step 2550: Loss = 1.6695 | BPC = 2.4085 | LR = 3.00e-04
Step 2560: Loss = 1.7484 | BPC = 2.5224 | LR = 3.00e-04
Step 2570: Loss = 1.8692 | BPC = 2.6967 | LR = 3.00e-04
Step 2580: Loss = 1.7489 | BPC = 2.5231 | LR = 3.00e-04
Step 2590: Loss = 1.6611 | BPC = 2.3964 | LR = 3.00e-04
Step 2600: Loss = 1.6945 | BPC = 2.4446 | LR = 3.00e-04
-- VALIDATION: Loss = 1.6717 | BPC = 2.4118 --
Saved best model (Turkish).
Step 2610: Loss = 1.8138 | BPC = 2.6168 | LR = 3.00e-04
Step 2620: Loss = 1.6625 | BPC = 2.3985 | LR = 3.00e-04
Step 2630: Loss = 1.7228 | BPC = 2.4854 | LR = 3.00e-04
Step 2640: Loss = 1.8917 | BPC = 2.7292 | LR = 3.00e-04
Step 2650: Loss = 1.5369 | BPC = 2.2173 | LR = 3.00e-04
Step 2660: Loss = 1.7377 | BPC = 2.5070 | LR = 3.00e-04
Step 2670: Loss = 1.7857 | BPC = 2.5763 | LR = 3.00e-04
Step 2680: Loss = 1.7066 | BPC = 2.4621 | LR = 3.00e-04
Step 2690: Loss = 1.6314 | BPC = 2.3537 | LR = 3.00e-04
Step 2700: Loss = 1.5805 | BPC = 2.2802 | LR = 3.00e-04
Step 2710: Loss = 1.7114 | BPC = 2.4690 | LR = 3.00e-04
Step 2720: Loss = 1.5588 | BPC = 2.2488 | LR = 3.00e-04
Step 2730: Loss = 1.6580 | BPC = 2.3920 | LR = 3.00e-04
Step 2740: Loss = 1.5470 | BPC = 2.2319 | LR = 3.00e-04
Step 2750: Loss = 1.6250 | BPC = 2.3444 | LR = 3.00e-04
Step 2760: Loss = 1.7886 | BPC = 2.5805 | LR = 3.00e-04
Step 2770: Loss = 1.8185 | BPC = 2.6235 | LR = 3.00e-04
Step 2780: Loss = 1.9213 | BPC = 2.7719 | LR = 3.00e-04
Step 2790: Loss = 1.5399 | BPC = 2.2217 | LR = 3.00e-04
Step 2800: Loss = 1.7652 | BPC = 2.5467 | LR = 3.00e-04
-- VALIDATION: Loss = 1.6617 | BPC = 2.3974 --
Saved best model (Turkish).
Step 2810: Loss = 1.4923 | BPC = 2.1529 | LR = 3.00e-04
Step 2820: Loss = 1.6832 | BPC = 2.4283 | LR = 3.00e-04
Step 2830: Loss = 2.1025 | BPC = 3.0333 | LR = 3.00e-04
Step 2840: Loss = 1.7899 | BPC = 2.5822 | LR = 3.00e-04
Step 2850: Loss = 1.7381 | BPC = 2.5075 | LR = 3.00e-04
Step 2860: Loss = 1.7394 | BPC = 2.5095 | LR = 3.00e-04
Step 2870: Loss = 1.6373 | BPC = 2.3622 | LR = 3.00e-04
Step 2880: Loss = 1.7920 | BPC = 2.5854 | LR = 3.00e-04
Step 2890: Loss = 1.9845 | BPC = 2.8631 | LR = 3.00e-04
Step 2900: Loss = 1.7079 | BPC = 2.4640 | LR = 3.00e-04
Step 2910: Loss = 1.5798 | BPC = 2.2792 | LR = 3.00e-04
Step 2920: Loss = 1.5929 | BPC = 2.2980 | LR = 3.00e-04
Step 2930: Loss = 1.8471 | BPC = 2.6648 | LR = 3.00e-04
Step 2940: Loss = 1.6381 | BPC = 2.3633 | LR = 3.00e-04
Step 2950: Loss = 1.8838 | BPC = 2.7177 | LR = 3.00e-04
Step 2960: Loss = 1.7658 | BPC = 2.5475 | LR = 3.00e-04
Step 2970: Loss = 1.5990 | BPC = 2.3068 | LR = 3.00e-04
Step 2980: Loss = 1.5930 | BPC = 2.2982 | LR = 3.00e-04
Step 2990: Loss = 1.5912 | BPC = 2.2956 | LR = 3.00e-04
Step 3000: Loss = 1.6174 | BPC = 2.3334 | LR = 3.00e-04
-- VALIDATION: Loss = 1.6371 | BPC = 2.3618 --
Saved best model (Turkish).
Step 3010: Loss = 1.5952 | BPC = 2.3014 | LR = 3.00e-04
Step 3020: Loss = 1.7841 | BPC = 2.5739 | LR = 3.00e-04
Step 3030: Loss = 1.5778 | BPC = 2.2763 | LR = 3.00e-04
Step 3040: Loss = 1.6399 | BPC = 2.3658 | LR = 3.00e-04
Step 3050: Loss = 1.6078 | BPC = 2.3195 | LR = 3.00e-04
Step 3060: Loss = 1.8745 | BPC = 2.7043 | LR = 3.00e-04
Step 3070: Loss = 2.0907 | BPC = 3.0163 | LR = 3.00e-04
Step 3080: Loss = 1.6727 | BPC = 2.4132 | LR = 3.00e-04
Step 3090: Loss = 1.5505 | BPC = 2.2369 | LR = 3.00e-04
Step 3100: Loss = 1.8765 | BPC = 2.7071 | LR = 3.00e-04
Step 3110: Loss = 1.6709 | BPC = 2.4106 | LR = 3.00e-04
Step 3120: Loss = 2.0066 | BPC = 2.8949 | LR = 3.00e-04
Step 3130: Loss = 1.6348 | BPC = 2.3586 | LR = 3.00e-04
Step 3140: Loss = 1.5793 | BPC = 2.2785 | LR = 3.00e-04
Step 3150: Loss = 1.8974 | BPC = 2.7373 | LR = 3.00e-04
Step 3160: Loss = 1.7043 | BPC = 2.4588 | LR = 3.00e-04
Step 3170: Loss = 1.6968 | BPC = 2.4479 | LR = 3.00e-04
Step 3180: Loss = 1.6798 | BPC = 2.4234 | LR = 3.00e-04
Step 3190: Loss = 1.6559 | BPC = 2.3890 | LR = 3.00e-04
Step 3200: Loss = 1.7429 | BPC = 2.5144 | LR = 3.00e-04
-- VALIDATION: Loss = 1.6439 | BPC = 2.3716 --
Step 3210: Loss = 1.7075 | BPC = 2.4635 | LR = 3.00e-04
Step 3220: Loss = 1.6209 | BPC = 2.3385 | LR = 3.00e-04
Step 3230: Loss = 1.9853 | BPC = 2.8642 | LR = 3.00e-04
Step 3240: Loss = 1.8447 | BPC = 2.6614 | LR = 3.00e-04
Step 3250: Loss = 1.7068 | BPC = 2.4623 | LR = 3.00e-04
Step 3260: Loss = 1.6138 | BPC = 2.3282 | LR = 3.00e-04
Step 3270: Loss = 1.6782 | BPC = 2.4211 | LR = 3.00e-04
Step 3280: Loss = 1.7143 | BPC = 2.4732 | LR = 3.00e-04
Step 3290: Loss = 1.6600 | BPC = 2.3949 | LR = 3.00e-04
Step 3300: Loss = 1.6992 | BPC = 2.4514 | LR = 3.00e-04
Step 3310: Loss = 1.7074 | BPC = 2.4633 | LR = 3.00e-04
Step 3320: Loss = 1.6687 | BPC = 2.4074 | LR = 3.00e-04
Step 3330: Loss = 1.6573 | BPC = 2.3910 | LR = 3.00e-04
Step 3340: Loss = 1.5195 | BPC = 2.1922 | LR = 3.00e-04
Step 3350: Loss = 1.7632 | BPC = 2.5437 | LR = 3.00e-04
Step 3360: Loss = 1.5475 | BPC = 2.2325 | LR = 3.00e-04
Step 3370: Loss = 1.5973 | BPC = 2.3045 | LR = 3.00e-04
Step 3380: Loss = 1.5079 | BPC = 2.1754 | LR = 3.00e-04
Step 3390: Loss = 1.5575 | BPC = 2.2470 | LR = 3.00e-04
Step 3400: Loss = 1.6673 | BPC = 2.4053 | LR = 3.00e-04
-- VALIDATION: Loss = 1.6171 | BPC = 2.3330 --
Saved best model (Turkish).
Step 3410: Loss = 1.5034 | BPC = 2.1689 | LR = 3.00e-04
Step 3420: Loss = 1.6937 | BPC = 2.4434 | LR = 3.00e-04
Step 3430: Loss = 1.6743 | BPC = 2.4155 | LR = 3.00e-04
Step 3440: Loss = 1.7811 | BPC = 2.5695 | LR = 3.00e-04
Step 3450: Loss = 1.5651 | BPC = 2.2580 | LR = 3.00e-04
Step 3460: Loss = 1.5817 | BPC = 2.2819 | LR = 3.00e-04
Step 3470: Loss = 1.9928 | BPC = 2.8749 | LR = 3.00e-04
Step 3480: Loss = 1.5805 | BPC = 2.2802 | LR = 3.00e-04
Step 3490: Loss = 1.6071 | BPC = 2.3185 | LR = 3.00e-04
Step 3500: Loss = 1.5128 | BPC = 2.1825 | LR = 3.00e-04
Step 3510: Loss = 1.5810 | BPC = 2.2809 | LR = 3.00e-04
Step 3520: Loss = 1.6719 | BPC = 2.4120 | LR = 3.00e-04
Step 3530: Loss = 1.5725 | BPC = 2.2686 | LR = 3.00e-04
Step 3540: Loss = 1.6501 | BPC = 2.3805 | LR = 3.00e-04
Step 3550: Loss = 1.5568 | BPC = 2.2460 | LR = 3.00e-04
Step 3560: Loss = 1.6277 | BPC = 2.3483 | LR = 3.00e-04
Step 3570: Loss = 1.6034 | BPC = 2.3132 | LR = 3.00e-04
Step 3580: Loss = 1.6392 | BPC = 2.3648 | LR = 3.00e-04
Step 3590: Loss = 1.5476 | BPC = 2.2327 | LR = 3.00e-04
Step 3600: Loss = 1.5864 | BPC = 2.2888 | LR = 3.00e-04
-- VALIDATION: Loss = 1.6067 | BPC = 2.3179 --
Saved best model (Turkish).
Step 3610: Loss = 1.5406 | BPC = 2.2226 | LR = 3.00e-04
Step 3620: Loss = 1.7775 | BPC = 2.5643 | LR = 3.00e-04
Step 3630: Loss = 1.5104 | BPC = 2.1790 | LR = 3.00e-04
Step 3640: Loss = 1.5683 | BPC = 2.2626 | LR = 3.00e-04
Step 3650: Loss = 1.5487 | BPC = 2.2344 | LR = 3.00e-04
Step 3660: Loss = 1.8678 | BPC = 2.6946 | LR = 3.00e-04
Step 3670: Loss = 1.5718 | BPC = 2.2676 | LR = 3.00e-04
Step 3680: Loss = 1.4988 | BPC = 2.1623 | LR = 3.00e-04
Step 3690: Loss = 1.7535 | BPC = 2.5298 | LR = 3.00e-04
Step 3700: Loss = 1.6072 | BPC = 2.3188 | LR = 3.00e-04
Step 3710: Loss = 1.6916 | BPC = 2.4405 | LR = 3.00e-04
Step 3720: Loss = 1.5365 | BPC = 2.2167 | LR = 3.00e-04
Step 3730: Loss = 1.6494 | BPC = 2.3795 | LR = 3.00e-04
Step 3740: Loss = 1.7291 | BPC = 2.4946 | LR = 3.00e-04
Step 3750: Loss = 1.5371 | BPC = 2.2175 | LR = 3.00e-04
Step 3760: Loss = 1.7094 | BPC = 2.4662 | LR = 3.00e-04
Step 3770: Loss = 1.7435 | BPC = 2.5153 | LR = 3.00e-04
Step 3780: Loss = 1.6021 | BPC = 2.3114 | LR = 3.00e-04
Step 3790: Loss = 1.5007 | BPC = 2.1651 | LR = 3.00e-04
Step 3800: Loss = 1.5579 | BPC = 2.2475 | LR = 3.00e-04
-- VALIDATION: Loss = 1.6123 | BPC = 2.3261 --
Step 3810: Loss = 1.5664 | BPC = 2.2599 | LR = 3.00e-04
Step 3820: Loss = 1.8751 | BPC = 2.7052 | LR = 3.00e-04
Step 3830: Loss = 1.5466 | BPC = 2.2313 | LR = 3.00e-04
Step 3840: Loss = 1.6007 | BPC = 2.3093 | LR = 3.00e-04
Step 3850: Loss = 1.8044 | BPC = 2.6032 | LR = 3.00e-04
Step 3860: Loss = 1.9861 | BPC = 2.8654 | LR = 3.00e-04
Step 3870: Loss = 1.6499 | BPC = 2.3803 | LR = 3.00e-04
Step 3880: Loss = 1.7333 | BPC = 2.5007 | LR = 3.00e-04
Step 3890: Loss = 1.6065 | BPC = 2.3176 | LR = 3.00e-04
Step 3900: Loss = 1.8760 | BPC = 2.7065 | LR = 3.00e-04
Step 3910: Loss = 1.4517 | BPC = 2.0944 | LR = 3.00e-04
Step 3920: Loss = 1.5911 | BPC = 2.2955 | LR = 3.00e-04
Step 3930: Loss = 1.5581 | BPC = 2.2478 | LR = 3.00e-04
Step 3940: Loss = 1.5586 | BPC = 2.2486 | LR = 3.00e-04
Step 3950: Loss = 1.4807 | BPC = 2.1362 | LR = 3.00e-04
Step 3960: Loss = 1.7115 | BPC = 2.4692 | LR = 3.00e-04
Step 3970: Loss = 1.6216 | BPC = 2.3395 | LR = 3.00e-04
Step 3980: Loss = 1.5122 | BPC = 2.1817 | LR = 3.00e-04
Step 3990: Loss = 1.5421 | BPC = 2.2247 | LR = 3.00e-04
Step 4000: Loss = 1.4963 | BPC = 2.1587 | LR = 3.00e-04
-- VALIDATION: Loss = 1.5991 | BPC = 2.3070 --
Saved best model (Turkish).
Step 4010: Loss = 1.8268 | BPC = 2.6355 | LR = 3.00e-04
Step 4020: Loss = 1.5962 | BPC = 2.3028 | LR = 3.00e-04
Step 4030: Loss = 1.5952 | BPC = 2.3013 | LR = 3.00e-04
Step 4040: Loss = 1.6107 | BPC = 2.3237 | LR = 3.00e-04
Step 4050: Loss = 1.6901 | BPC = 2.4384 | LR = 3.00e-04
Step 4060: Loss = 1.5013 | BPC = 2.1659 | LR = 3.00e-04
Step 4070: Loss = 1.7346 | BPC = 2.5025 | LR = 3.00e-04
Step 4080: Loss = 1.6823 | BPC = 2.4271 | LR = 3.00e-04
Step 4090: Loss = 1.6659 | BPC = 2.4033 | LR = 3.00e-04
Step 4100: Loss = 1.5865 | BPC = 2.2889 | LR = 3.00e-04
Step 4110: Loss = 1.6450 | BPC = 2.3733 | LR = 3.00e-04
Step 4120: Loss = 1.7008 | BPC = 2.4538 | LR = 3.00e-04
Step 4130: Loss = 1.4857 | BPC = 2.1434 | LR = 3.00e-04
Step 4140: Loss = 1.5766 | BPC = 2.2745 | LR = 3.00e-04
Step 4150: Loss = 1.8988 | BPC = 2.7393 | LR = 3.00e-04
Step 4160: Loss = 1.7423 | BPC = 2.5136 | LR = 3.00e-04
Step 4170: Loss = 1.5201 | BPC = 2.1930 | LR = 3.00e-04
Step 4180: Loss = 1.5499 | BPC = 2.2360 | LR = 3.00e-04
Step 4190: Loss = 1.5167 | BPC = 2.1882 | LR = 3.00e-04
Step 4200: Loss = 1.5906 | BPC = 2.2948 | LR = 3.00e-04
-- VALIDATION: Loss = 1.5971 | BPC = 2.3041 --
Saved best model (Turkish).
Step 4210: Loss = 1.5180 | BPC = 2.1901 | LR = 3.00e-04
Step 4220: Loss = 1.5538 | BPC = 2.2417 | LR = 3.00e-04
Step 4230: Loss = 1.7319 | BPC = 2.4985 | LR = 3.00e-04
Step 4240: Loss = 1.5369 | BPC = 2.2172 | LR = 3.00e-04
Step 4250: Loss = 1.6364 | BPC = 2.3609 | LR = 3.00e-04
Step 4260: Loss = 1.5312 | BPC = 2.2091 | LR = 3.00e-04
Step 4270: Loss = 1.5745 | BPC = 2.2716 | LR = 3.00e-04
Step 4280: Loss = 1.6340 | BPC = 2.3574 | LR = 3.00e-04
Step 4290: Loss = 1.6777 | BPC = 2.4204 | LR = 3.00e-04
Step 4300: Loss = 1.6188 | BPC = 2.3354 | LR = 3.00e-04
Step 4310: Loss = 1.5732 | BPC = 2.2696 | LR = 3.00e-04
Step 4320: Loss = 1.5550 | BPC = 2.2434 | LR = 3.00e-04
Step 4330: Loss = 1.6166 | BPC = 2.3323 | LR = 3.00e-04
Step 4340: Loss = 1.4902 | BPC = 2.1499 | LR = 3.00e-04
Step 4350: Loss = 1.5734 | BPC = 2.2699 | LR = 3.00e-04
Step 4360: Loss = 1.5941 | BPC = 2.2999 | LR = 3.00e-04
Step 4370: Loss = 1.5116 | BPC = 2.1808 | LR = 3.00e-04
Step 4380: Loss = 1.8167 | BPC = 2.6210 | LR = 3.00e-04
Step 4390: Loss = 1.5227 | BPC = 2.1967 | LR = 3.00e-04
Step 4400: Loss = 1.6587 | BPC = 2.3931 | LR = 3.00e-04
-- VALIDATION: Loss = 1.5887 | BPC = 2.2919 --
Saved best model (Turkish).
Step 4410: Loss = 1.6895 | BPC = 2.4375 | LR = 3.00e-04
Step 4420: Loss = 1.5961 | BPC = 2.3027 | LR = 3.00e-04
Step 4430: Loss = 1.8224 | BPC = 2.6291 | LR = 3.00e-04
Step 4440: Loss = 1.6928 | BPC = 2.4423 | LR = 3.00e-04
Step 4450: Loss = 1.5514 | BPC = 2.2382 | LR = 3.00e-04
Step 4460: Loss = 1.6289 | BPC = 2.3500 | LR = 3.00e-04
Step 4470: Loss = 1.5578 | BPC = 2.2475 | LR = 3.00e-04
Step 4480: Loss = 1.6283 | BPC = 2.3491 | LR = 3.00e-04
Step 4490: Loss = 1.8254 | BPC = 2.6335 | LR = 3.00e-04
Step 4500: Loss = 1.5360 | BPC = 2.2160 | LR = 3.00e-04
Step 4510: Loss = 1.5780 | BPC = 2.2765 | LR = 3.00e-04
Step 4520: Loss = 1.6651 | BPC = 2.4023 | LR = 3.00e-04
Step 4530: Loss = 1.6506 | BPC = 2.3814 | LR = 3.00e-04
Step 4540: Loss = 1.4734 | BPC = 2.1256 | LR = 3.00e-04
Step 4550: Loss = 1.8271 | BPC = 2.6360 | LR = 3.00e-04
Step 4560: Loss = 1.8111 | BPC = 2.6129 | LR = 3.00e-04
Step 4570: Loss = 1.5296 | BPC = 2.2067 | LR = 3.00e-04
Step 4580: Loss = 1.6517 | BPC = 2.3829 | LR = 3.00e-04
Step 4590: Loss = 1.6094 | BPC = 2.3218 | LR = 3.00e-04
Step 4600: Loss = 1.4767 | BPC = 2.1304 | LR = 3.00e-04
-- VALIDATION: Loss = 1.5829 | BPC = 2.2836 --
Saved best model (Turkish).
Step 4610: Loss = 1.5816 | BPC = 2.2818 | LR = 3.00e-04
Step 4620: Loss = 1.4603 | BPC = 2.1068 | LR = 3.00e-04
Step 4630: Loss = 1.5900 | BPC = 2.2939 | LR = 3.00e-04
Step 4640: Loss = 1.6291 | BPC = 2.3503 | LR = 3.00e-04
Step 4650: Loss = 1.6425 | BPC = 2.3697 | LR = 3.00e-04
Step 4660: Loss = 1.6473 | BPC = 2.3765 | LR = 3.00e-04
Step 4670: Loss = 1.7263 | BPC = 2.4905 | LR = 3.00e-04
Step 4680: Loss = 1.7235 | BPC = 2.4864 | LR = 3.00e-04
Step 4690: Loss = 1.6183 | BPC = 2.3347 | LR = 3.00e-04
Step 4700: Loss = 1.4864 | BPC = 2.1444 | LR = 3.00e-04
Step 4710: Loss = 1.6100 | BPC = 2.3228 | LR = 3.00e-04
Step 4720: Loss = 1.4589 | BPC = 2.1047 | LR = 3.00e-04
Step 4730: Loss = 1.7391 | BPC = 2.5090 | LR = 3.00e-04
Step 4740: Loss = 1.7663 | BPC = 2.5483 | LR = 3.00e-04
Step 4750: Loss = 1.7356 | BPC = 2.5040 | LR = 3.00e-04
Step 4760: Loss = 1.5643 | BPC = 2.2568 | LR = 3.00e-04
Step 4770: Loss = 1.5294 | BPC = 2.2064 | LR = 3.00e-04
Step 4780: Loss = 1.6649 | BPC = 2.4020 | LR = 3.00e-04
Step 4790: Loss = 1.6190 | BPC = 2.3357 | LR = 3.00e-04
Step 4800: Loss = 1.6430 | BPC = 2.3703 | LR = 3.00e-04
-- VALIDATION: Loss = 1.5739 | BPC = 2.2706 --
Saved best model (Turkish).
Step 4810: Loss = 1.7427 | BPC = 2.5142 | LR = 3.00e-04
Step 4820: Loss = 1.6594 | BPC = 2.3940 | LR = 3.00e-04
Step 4830: Loss = 1.5798 | BPC = 2.2792 | LR = 3.00e-04
Step 4840: Loss = 1.6531 | BPC = 2.3849 | LR = 3.00e-04
Step 4850: Loss = 1.6617 | BPC = 2.3973 | LR = 3.00e-04
Step 4860: Loss = 1.5097 | BPC = 2.1780 | LR = 3.00e-04
Step 4870: Loss = 1.4841 | BPC = 2.1411 | LR = 3.00e-04
Step 4880: Loss = 1.5234 | BPC = 2.1979 | LR = 3.00e-04
Step 4890: Loss = 1.5639 | BPC = 2.2562 | LR = 3.00e-04
Step 4900: Loss = 1.7395 | BPC = 2.5095 | LR = 3.00e-04
Step 4910: Loss = 1.7400 | BPC = 2.5103 | LR = 3.00e-04
Step 4920: Loss = 1.5782 | BPC = 2.2768 | LR = 3.00e-04
Step 4930: Loss = 1.5367 | BPC = 2.2170 | LR = 3.00e-04
Step 4940: Loss = 1.7618 | BPC = 2.5417 | LR = 3.00e-04
Step 4950: Loss = 1.3866 | BPC = 2.0004 | LR = 3.00e-04
Step 4960: Loss = 1.8761 | BPC = 2.7066 | LR = 3.00e-04
Step 4970: Loss = 1.6937 | BPC = 2.4434 | LR = 3.00e-04
Step 4980: Loss = 1.7094 | BPC = 2.4662 | LR = 3.00e-04
Step 4990: Loss = 1.5289 | BPC = 2.2057 | LR = 3.00e-04
Saving last model state...
Saved last_model_turkish.pth
Training finished in 690.92s
Final validation BPC: 2.2706
